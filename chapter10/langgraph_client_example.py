import asyncio
import warnings
from typing import TypedDict, Annotated, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langgraph.warnings import LangGraphDeprecatedSinceV10
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from pydantic import create_model
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from init_client import init_llm

# å¿½ç•¥ LangGraph çš„åºŸå¼ƒè­¦å‘Š
warnings.filterwarnings("ignore", category=LangGraphDeprecatedSinceV10)


# å®šä¹‰çŠ¶æ€
class AgentState(TypedDict):
    messages: Annotated[List, "æ¶ˆæ¯åˆ—è¡¨"]
    current_order: dict
    inventory_status: dict
    purchase_request: dict
    shipping_order: dict


class MCPToolManager:
    """ä¸€ä¸ªç”¨äºç®¡ç† MCP è¿æ¥å’Œå·¥å…·ç”Ÿå‘½å‘¨æœŸçš„ç±»ã€‚"""

    def __init__(self, server_script: str):
        self.server_script = server_script
        self.session: ClientSession | None = None
        self.tools = []
        self._stdio_cm = None
        self._session_cm = None

    async def connect(self):
        server_params = StdioServerParameters(
            command="python", args=[self.server_script]
        )
        self._stdio_cm = stdio_client(server_params)
        read, write = await self._stdio_cm.__aenter__()

        self._session_cm = ClientSession(read, write)
        self.session = await self._session_cm.__aenter__()

        await self.session.initialize()
        print("âœ… MCP æœåŠ¡å™¨è¿æ¥æˆåŠŸã€‚")

    async def load_tools(self):
        if not self.session:
            raise RuntimeError("æœªè¿æ¥åˆ° MCP æœåŠ¡å™¨ã€‚è¯·å…ˆè°ƒç”¨ connect()ã€‚")

        response = await self.session.list_tools()

        self.tools = []
        for mcp_tool in response.tools:
            tool_name = mcp_tool.name
            tool_desc = mcp_tool.description
            input_schema = mcp_tool.inputSchema

            # åŠ¨æ€åˆ›å»º Pydantic æ¨¡å‹ä½œä¸º args_schema
            fields = {}
            required_fields = input_schema.get("required", [])
            for prop_name, prop_details in input_schema.get("properties", {}).items():
                prop_type = prop_details.get("type")
                python_type = str
                if prop_type == "number":
                    python_type = float
                elif prop_type == "integer":
                    python_type = int
                elif prop_type == "array":
                    python_type = list

                if prop_name in required_fields:
                    fields[prop_name] = (python_type, ...)
                else:
                    fields[prop_name] = (python_type, None)

            dynamic_args_model = create_model(f'{tool_name}Args', **fields)

            async def make_call_tool(s, tn):
                async def call_tool(**kwargs):
                    result = await s.call_tool(tn, arguments=kwargs)
                    return result.content[0].text

                return call_tool

            actual_call_tool = await make_call_tool(self.session, tool_name)
            actual_call_tool.__name__ = tool_name
            actual_call_tool.__doc__ = tool_desc

            langchain_tool = tool(actual_call_tool)
            langchain_tool.args_schema = dynamic_args_model

            self.tools.append(langchain_tool)

        print(f"âœ… æˆåŠŸä» MCP æœåŠ¡å™¨åŠ è½½äº† {len(self.tools)} ä¸ªå·¥å…·ã€‚")

    async def close(self):
        if self.session and self._session_cm:
            await self._session_cm.__aexit__(None, None, None)
            self.session = None
            self._session_cm = None
        if self._stdio_cm:
            await self._stdio_cm.__aexit__(None, None, None)
            self._stdio_cm = None
        print("ğŸ”Œ MCP æœåŠ¡å™¨è¿æ¥å·²å…³é—­ã€‚")


# ä¸»æ‰§è¡Œé€»è¾‘
async def main():
    manager = MCPToolManager("mcp_utility_server.py")

    try:
        await manager.connect()
        await manager.load_tools()

        if not manager.tools:
            print("æœªèƒ½ä»MCPæœåŠ¡å™¨åŠ è½½ä»»ä½•å·¥å…·ã€‚")
            return

        # åˆå§‹åŒ– DeepSeek æ¨¡å‹
        llm = init_llm(
            temperature=0
        )

        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šçº§é”€å”®è®¢å•å¤„ç†ä¸“å®¶ï¼Œè´Ÿè´£åè°ƒå’Œè‡ªåŠ¨åŒ–å¤„ç†é”€å”®è®¢å•æµç¨‹ã€‚

        ä½ çš„å·¥ä½œæµç¨‹åŒ…æ‹¬ï¼š
        1. æ¥æ”¶æ–°çš„é”€å”®è®¢å•
        2. æ£€æŸ¥åº“å­˜æ˜¯å¦å……è¶³
        3. å¦‚æœåº“å­˜ä¸è¶³ï¼Œåˆ›å»ºé‡‡è´­ç”³è¯·å¹¶ç­‰å¾…æ‰¹å‡†
        4. æ‰¹å‡†é‡‡è´­ç”³è¯·åï¼Œæ›´æ–°åº“å­˜
        5. åˆ›å»ºå‘è´§å•å¹¶æ›´æ–°åº“å­˜
        6. å‘é€é€šçŸ¥ç»™ç›¸å…³äººå‘˜

        è¯·å§‹ç»ˆéµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
        - ç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æ­£ç¡®å®Œæˆåå†è¿›è¡Œä¸‹ä¸€æ­¥
        - åœ¨åº“å­˜ä¸è¶³æ—¶ï¼Œå¿…é¡»åˆ›å»ºé‡‡è´­ç”³è¯·
        - åœ¨åˆ›å»ºå‘è´§å•å‰ï¼Œç¡®ä¿åº“å­˜å……è¶³
        - åœ¨å…³é”®æ­¥éª¤å®Œæˆåï¼Œå‘é€é€šçŸ¥ç»™ç›¸å…³äººå‘˜
        - å§‹ç»ˆä¿æŒä¸“ä¸šå’Œé«˜æ•ˆ
        è¯·ä½¿ç”¨ä¸­æ–‡è¿›è¡Œæ€è€ƒå’Œå›ç­”ã€‚
        """

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("placeholder", "{messages}"),
        ])

        tools_dict = {tool.name: tool for tool in manager.tools}

        # èŠ‚ç‚¹å‡½æ•°ä¿æŒä¸å˜...
        async def call_model(state: AgentState):
            messages = state["messages"]
            response = await llm.ainvoke(prompt.format_messages(messages=messages))
            return {"messages": [response]}

        async def call_tool(state: AgentState):
            messages = state["messages"]
            last_message = messages[-1]

            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                tool_call = last_message.tool_calls[0]
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]

                if tool_name in tools_dict:
                    tool_result = await tools_dict[tool_name].ainvoke(tool_args)
                    # ä½¿ç”¨ ToolMessage æ¥è¡¨ç¤ºå·¥å…·è¿”å›çš„ç»“æœ
                    from langchain_core.messages import ToolMessage
                    tool_message = ToolMessage(
                        content=tool_result,
                        tool_call_id=tool_call["id"]
                    )
                    return {"messages": [tool_message]}

            return {"messages": []}

        def should_continue(state: AgentState):
            messages = state["messages"]
            last_message = messages[-1]

            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"

            return END

        workflow = StateGraph(AgentState)

        workflow.add_node("agent", call_model)
        workflow.add_node("tools", call_tool)

        workflow.set_entry_point("agent")

        workflow.add_conditional_edges(
            "agent",
            should_continue,
        )

        workflow.add_edge("tools", "agent")

        memory = MemorySaver()

        app = workflow.compile(checkpointer=memory)

        # --- æ·»åŠ  config å‚æ•° ---
        config = {"configurable": {"thread_id": "order-processing-thread-1"}}

        # äº¤äº’å¾ªç¯
        while True:
            user_input = input("ä½ : ")
            if user_input.lower() in ['quit', 'exit', 'q']:
                break

            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "current_order": {},
                "inventory_status": {},
                "purchase_request": {},
                "shipping_order": {}
            }

            print("Agent: ", end="", flush=True)
            # --- åœ¨ astream ä¸­ä¼ å…¥ config ---
            async for event in app.astream(initial_state, config):
                for node, output in event.items():
                    if node == "agent" and "messages" in output:
                        for message in output["messages"]:
                            if hasattr(message, 'content') and message.content:
                                print(message.content, end="", flush=True)
                    elif node == "tools" and "messages" in output:
                        for message in output["messages"]:
                            if hasattr(message, 'content') and message.content:
                                print(f"\n[å·¥å…·æ‰§è¡Œç»“æœ]: {message.content}", end="", flush=True)
            print("\n", end="", flush=True)

    finally:
        await manager.close()


if __name__ == "__main__":
    asyncio.run(main())

    '''
    ä½ ï¼šæˆ‘éœ€è¦å¤„ç†ä¸€ä¸ªæ–°çš„é”€å”®è®¢å•ï¼Œè®¢å•IDæ˜¯SO-2023-001ï¼Œå®¢æˆ·IDæ˜¯CUST-001ï¼ŒåŒ…å«ä»¥ä¸‹é¡¹ç›®ï¼š2å°å•†åŠ¡ç¬”è®°æœ¬(LAPTOP-001)ï¼Œ10ä¸ªæ— çº¿é¼ æ ‡(MOUSE-001)ï¼Œ5ä¸ªæœºæ¢°é”®ç›˜(KEYBOARD-001)

    ä½ ï¼šæˆ‘éœ€è¦å¤„ç†ä¸€ä¸ªæ–°çš„é”€å”®è®¢å•ï¼Œè®¢å•IDæ˜¯SO-2023-002ï¼Œå®¢æˆ·IDæ˜¯CUST-002ï¼ŒåŒ…å«ä»¥ä¸‹é¡¹ç›®ï¼š3å°27å¯¸æ˜¾ç¤ºå™¨(MONITOR-001)ï¼Œ5ä¸ªæœºæ¢°é”®ç›˜(KEYBOARD-001)
    ä½ ï¼šæˆ‘æ˜¯é‡‡è´­ç»ç†ï¼Œæˆ‘éœ€è¦æ‰¹å‡†é‡‡è´­ç”³è¯· PR-20231115103520
    '''