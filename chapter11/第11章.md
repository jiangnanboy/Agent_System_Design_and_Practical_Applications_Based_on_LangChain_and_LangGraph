# æ™ºèƒ½ä½“å®æˆ˜ä¹‹ç›®æ ‡è®¾å®šä¸ç›‘æ§ï¼šå®ç°è‡ªä¸»æ™ºèƒ½çš„å…³é”®
![ç›®æ ‡è®¾å®šä¸ç›‘æ§](chapter11.png)

## ä¸€.ç®€ä»‹

åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œä¸€ä¸ªçœŸæ­£æœ‰æ•ˆçš„Agentä¸ä»…éœ€è¦å¤„ç†ä¿¡æ¯å’Œä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ï¼Œæ›´éœ€è¦æ˜ç¡®çš„ç›®æ ‡å¯¼å‘å’Œè‡ªæˆ‘è¯„ä¼°æœºåˆ¶ã€‚ç›®æ ‡è®¾å®šå’Œç›‘æ§æ¨¡å¼æ­£æ˜¯èµ‹äºˆAI Agentè¿™ç§æ–¹å‘æ„Ÿå’ŒæˆåŠŸåˆ¤æ–­èƒ½åŠ›çš„æ ¸å¿ƒæ¡†æ¶ï¼Œå®ƒå°†ç®€å•çš„ååº”ç³»ç»Ÿè½¬å˜ä¸ºèƒ½å¤Ÿä¸»åŠ¨æœç€å®šä¹‰ç›®æ ‡å·¥ä½œçš„æ™ºèƒ½å®ä½“ã€‚

### ç›®æ ‡è®¾å®šä¸ç›‘æ§æ¨¡å¼çš„æ ¸å¿ƒæ¦‚å¿µ

ç›®æ ‡è®¾å®šå’Œç›‘æ§æ¨¡å¼æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªè®©AI Agentå…·å¤‡"æ„å›¾-è¡ŒåŠ¨-è¯„ä¼°"å¾ªç¯çš„æ¡†æ¶ã€‚æƒ³è±¡ä¸€ä¸‹ä½ ç»„ç»‡ä¸€åœºå¤§å‹ä¼šè®®çš„è¿‡ç¨‹ï¼šä½ éœ€è¦æ˜ç¡®ä¼šè®®ç›®æ ‡ï¼ˆå¦‚ä¿ƒè¿›è¡Œä¸šäº¤æµï¼‰ï¼Œè¯„ä¼°å½“å‰çŠ¶æ€ï¼ˆåœºåœ°ã€é¢„ç®—ã€äººå‘˜ï¼‰ï¼Œè§„åˆ’æ­¥éª¤ï¼ˆé‚€è¯·å˜‰å®¾ã€å®‰æ’è®®ç¨‹ã€å®£ä¼ æ¨å¹¿ï¼‰ï¼Œå¹¶åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸æ–­ç›‘æ§è¿›åº¦ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è®¡åˆ’ã€‚

åœ¨AI Agentçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œè¿™ç§æ¨¡å¼æ¶‰åŠä»¥ä¸‹å‡ ä¸ªå…³é”®ç¯èŠ‚ï¼š

1. **ç›®æ ‡å®šä¹‰**ï¼šå°†é«˜çº§ç›®æ ‡è½¬åŒ–ä¸ºå…·ä½“ã€å¯è¡¡é‡çš„å­ç›®æ ‡
2. **çŠ¶æ€æ„ŸçŸ¥**ï¼šç†è§£å½“å‰ç¯å¢ƒå’Œè‡ªèº«çŠ¶æ€
3. **è§„åˆ’ç”Ÿæˆ**ï¼šåˆ›å»ºä»åˆå§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è¡ŒåŠ¨åºåˆ—
4. **æ‰§è¡Œç›‘æ§**ï¼šè·Ÿè¸ªè¿›åº¦å¹¶è¯„ä¼°æ˜¯å¦æœç›®æ ‡å‰è¿›
5. **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®åé¦ˆé‡æ–°è§„åˆ’æˆ–è°ƒæ•´ç­–ç•¥

è¿™ç§æ¨¡å¼ä½¿Agentèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼Œé€‚åº”ç¯å¢ƒå˜åŒ–ï¼Œå¹¶åœ¨ä¸ç¡®å®šæ€§ä¸­ä¿æŒç›®æ ‡å¯¼å‘ã€‚

### å®é™…åº”ç”¨åœºæ™¯

ç›®æ ‡è®¾å®šå’Œç›‘æ§æ¨¡å¼åœ¨å¤šä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼š

- **æ™ºèƒ½å®¶å±…ç³»ç»Ÿ**ï¼šAgentçš„ç›®æ ‡å¯èƒ½æ˜¯"ä¼˜åŒ–å®¶åº­èƒ½æºæ¶ˆè€—åŒæ—¶ä¿æŒèˆ’é€‚åº¦"ï¼Œå®ƒæŒç»­ç›‘æ§æ¸©åº¦ã€å…‰ç…§ã€äººå‘˜æ´»åŠ¨ç­‰æ•°æ®ï¼ŒåŠ¨æ€è°ƒæ•´ç©ºè°ƒã€ç…§æ˜ç­‰è®¾å¤‡ã€‚

- **åŒ»ç–—è¯Šæ–­åŠ©æ‰‹**ï¼šç›®æ ‡æ˜¯"æé«˜è¯Šæ–­å‡†ç¡®æ€§å¹¶å‡å°‘è¯¯è¯Š"ï¼ŒAgentåˆ†ææ‚£è€…æ•°æ®ï¼Œæå‡ºåˆæ­¥è¯Šæ–­ï¼Œç„¶åæ ¹æ®æ–°ä¿¡æ¯å’Œä¸“å®¶åé¦ˆä¸æ–­ä¼˜åŒ–è¯Šæ–­æ–¹æ¡ˆã€‚

- **å†…å®¹åˆ›ä½œåŠ©æ‰‹**ï¼šç›®æ ‡æ˜¯"ç”Ÿæˆç¬¦åˆå“ç‰Œé£æ ¼ä¸”å¸å¼•ç›®æ ‡å—ä¼—çš„å†…å®¹"ï¼ŒAgentåˆ›å»ºåˆç¨¿ï¼Œè·å–åé¦ˆï¼Œåˆ†æå—ä¼—ååº”ï¼Œå¹¶è¿­ä»£æ”¹è¿›å†…å®¹ã€‚

- **ä¾›åº”é“¾ä¼˜åŒ–**ï¼šç›®æ ‡æ˜¯"æœ€å°åŒ–åº“å­˜æˆæœ¬åŒæ—¶ç¡®ä¿äº§å“å¯ç”¨æ€§"ï¼ŒAgentç›‘æ§éœ€æ±‚é¢„æµ‹ã€åº“å­˜æ°´å¹³å’Œç‰©æµçŠ¶æ€ï¼ŒåŠ¨æ€è°ƒæ•´è®¢è´­å’Œé…é€è®¡åˆ’ã€‚

ç›®æ ‡è®¾å®šå’Œç›‘æ§æ¨¡å¼æ˜¯æ„å»ºé«˜æ•ˆAI Agentçš„æ ¸å¿ƒæ¡†æ¶ã€‚å®ƒèµ‹äºˆAgentæ˜ç¡®çš„æ–¹å‘æ„Ÿå’Œè‡ªæˆ‘è¯„ä¼°èƒ½åŠ›ï¼Œä½¿Agentèƒ½å¤Ÿä»ç®€å•çš„ååº”ç³»ç»Ÿè½¬å˜ä¸ºä¸»åŠ¨çš„ã€ç›®æ ‡é©±åŠ¨çš„æ™ºèƒ½å®ä½“ã€‚é€šè¿‡è®¾å®šæ¸…æ™°çš„ç›®æ ‡ã€æŒç»­ç›‘æ§è¿›åº¦ã€å¹¶æ ¹æ®åé¦ˆåŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ŒAI Agentèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­è‡ªä¸»å®Œæˆä»»åŠ¡ï¼Œé€‚åº”å˜åŒ–ï¼Œå¹¶æŒç»­æ”¹è¿›æ€§èƒ½ã€‚

éšç€AIæŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œç›®æ ‡è®¾å®šå’Œç›‘æ§æ¨¡å¼å°†åœ¨æ›´å¤šé¢†åŸŸå‘æŒ¥å…³é”®ä½œç”¨ï¼Œæ¨åŠ¨AIç³»ç»Ÿä»å·¥å…·æ€§åº”ç”¨å‘çœŸæ­£çš„æ™ºèƒ½åŠ©æ‰‹è½¬å˜ã€‚è¿™ç§æ¨¡å¼ä¸ä»…æé«˜äº†AIç³»ç»Ÿçš„å¯é æ€§ï¼Œä¹Ÿå¢å¼ºäº†äººç±»å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œä¸ºæ„å»ºæ›´åŠ æ™ºèƒ½ã€è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## äºŒ.å®æˆ˜æ¡ˆä¾‹--
æ„å»ºä¸€ä¸ªæ™ºèƒ½è®ºæ–‡åˆ†æåŠ©æ‰‹Agentï¼Œå®ƒèƒ½è‡ªåŠ¨è§£æPDFè®ºæ–‡ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç¬¦åˆç‰¹å®šç›®æ ‡çš„æ‘˜è¦ã€‚

## ä¸‰.langchainå®ç°
```python
import os
import json
import re
from typing import List, Dict, Any, ClassVar
from pathlib import Path

# PDFå¤„ç†åº“
import pdfplumber

# LangChainç»„ä»¶
from langchain_classic.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_core.output_parsers import BaseOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

from init_client import init_llm

class PDFParser:
    """PDFè§£æå™¨ - ä½¿ç”¨RunnableLambdaåŒ…è£…"""

    def __init__(self):
        self.parser = RunnableLambda(self._parse_pdf)

    def _parse_pdf(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        pdf_path = inputs["pdf_path"]

        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")

        print(f"ğŸ“„ å¼€å§‹è§£æPDFæ–‡ä»¶: {pdf_path}")

        try:
            with pdfplumber.open(pdf_path) as pdf:
                text_content = []

                # æå–å‰10é¡µå†…å®¹ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                max_pages = min(len(pdf.pages), 10)
                for i in range(max_pages):
                    page = pdf.pages[i]
                    text = page.extract_text()
                    if text:
                        text_content.append(text)

                paper_text = "\n\n".join(text_content)

                # æ¸…ç†æ–‡æœ¬
                paper_text = re.sub(r'\s+', ' ', paper_text)
                paper_text = re.sub(r'[^\w\s\u4e00-\u9fff.,;:!?()[]{}"\'-]', '', paper_text)

                print(f"âœ… PDFè§£æå®Œæˆï¼Œå…±æå– {len(paper_text)} å­—ç¬¦")
                return {"paper_text": paper_text}

        except Exception as e:
            print(f"âŒ PDFè§£æå¤±è´¥: {e}")
            return {"paper_text": ""}


class PaperAnalysisOutputParser(BaseOutputParser[Dict[str, Any]]):
    """è®ºæ–‡åˆ†æè¾“å‡ºè§£æå™¨"""

    # å°† schemas å®šä¹‰ä¸ºç±»å˜é‡
    analysis_schemas: ClassVar[List[ResponseSchema]] = [
        ResponseSchema(name="title", description="è®ºæ–‡æ ‡é¢˜"),
        ResponseSchema(name="authors", description="è®ºæ–‡ä½œè€…åˆ—è¡¨"),
        ResponseSchema(name="abstract", description="è®ºæ–‡æ‘˜è¦"),
        ResponseSchema(name="key_findings", description="ä¸»è¦å‘ç°ï¼Œä»¥åˆ—è¡¨å½¢å¼å‘ˆç°"),
        ResponseSchema(name="methodology", description="ç ”ç©¶æ–¹æ³•ç®€è¿°"),
        ResponseSchema(name="limitations", description="ç ”ç©¶å±€é™æ€§"),
        ResponseSchema(name="future_work", description="æœªæ¥å·¥ä½œå»ºè®®")
    ]

    # ä½¿ç”¨ @property æŒ‰éœ€åˆ›å»ºè§£æå™¨å®ä¾‹
    @property
    def _parser(self) -> StructuredOutputParser:
        return StructuredOutputParser.from_response_schemas(self.analysis_schemas)

    def parse(self, text: str) -> Dict[str, Any]:
        try:
            return self._parser.parse(text)
        except Exception as e:
            print(f"âš ï¸ åˆ†æç»“æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”: {e}")
            return {"raw_analysis": text}

    def get_format_instructions(self) -> str:
        return self._parser.get_format_instructions()


class SummaryEvaluationOutputParser(BaseOutputParser[Dict[str, Any]]):
    """æ‘˜è¦è¯„ä¼°è¾“å‡ºè§£æå™¨"""

    # å°† schemas å®šä¹‰ä¸ºç±»å˜é‡
    evaluation_schemas: ClassVar[List[ResponseSchema]] = [
        ResponseSchema(name="meets_goals", description="æ‘˜è¦æ˜¯å¦æ»¡è¶³æ‰€æœ‰è®¾å®šç›®æ ‡ï¼Œå›ç­”'æ˜¯'æˆ–'å¦'"),
        ResponseSchema(name="accuracy_score", description="æ‘˜è¦å‡†ç¡®åº¦è¯„åˆ†ï¼Œ1-10"),
        ResponseSchema(name="clarity_score", description="æ‘˜è¦æ¸…æ™°åº¦è¯„åˆ†ï¼Œ1-10"),
        ResponseSchema(name="completeness_score", description="æ‘˜è¦å®Œæ•´æ€§è¯„åˆ†ï¼Œ1-10"),
        ResponseSchema(name="feedback", description="æ”¹è¿›å»ºè®®ï¼Œå¦‚æœä¸æ»¡è¶³ç›®æ ‡")
    ]

    # ä½¿ç”¨ @property æŒ‰éœ€åˆ›å»ºè§£æå™¨å®ä¾‹
    @property
    def _parser(self) -> StructuredOutputParser:
        return StructuredOutputParser.from_response_schemas(self.evaluation_schemas)

    def parse(self, text: str) -> Dict[str, Any]:
        try:
            return self._parser.parse(text)
        except Exception as e:
            print(f"âš ï¸ è¯„ä¼°ç»“æœè§£æå¤±è´¥: {e}")
            return {"error": str(e)}

    def get_format_instructions(self) -> str:
        return self._parser.get_format_instructions()


class IntelligentPaperAnalyzer:
    """æ™ºèƒ½è®ºæ–‡åˆ†æå™¨ - ä½¿ç”¨ç®¡é“æ“ä½œç¬¦æ„å»ºAgent"""

    def __init__(self, max_iterations: int = 3):
        """åˆå§‹åŒ–æ™ºèƒ½è®ºæ–‡åˆ†æå™¨"""
        self.llm = init_llm(
            temperature=0.1
        )
        self.max_iterations = max_iterations
        self.goals = []

        # åˆå§‹åŒ–ç»„ä»¶ - ç°åœ¨å¯ä»¥æ­£å¸¸å®ä¾‹åŒ–
        self.pdf_parser = PDFParser()
        self.analysis_parser = PaperAnalysisOutputParser()
        self.evaluation_parser = SummaryEvaluationOutputParser()

        # æ„å»ºåˆ†æç®¡é“
        self._build_analysis_pipeline()
        # æ„å»ºè¯„ä¼°ç®¡é“
        self._build_evaluation_pipeline()
        # æ„å»ºæ”¹è¿›ç®¡é“
        self._build_improvement_pipeline()

    def _build_analysis_pipeline(self):
        """æ„å»ºè®ºæ–‡åˆ†æç®¡é“"""
        # åˆ†ææç¤ºæ¨¡æ¿
        self.analysis_prompt = PromptTemplate(
            input_variables=["paper_text", "format_instructions"],
            template="""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹ç ”ç©¶è®ºæ–‡ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ã€‚
            
            {format_instructions}
            
            è®ºæ–‡å†…å®¹:
            {paper_text}
            
            è¯·ç¡®ä¿æå–çš„ä¿¡æ¯å‡†ç¡®å®Œæ•´ã€‚
                        """
        )

        # æ„å»ºåˆ†æç®¡é“
        self.analysis_pipeline = (
                RunnablePassthrough.assign(
                    format_instructions=lambda _: self.analysis_parser.get_format_instructions()
                )
                | self.analysis_prompt
                | self.llm
                | RunnableLambda(lambda x: x.content)
                | self.analysis_parser
        )

    def _build_evaluation_pipeline(self):
        """æ„å»ºæ‘˜è¦è¯„ä¼°ç®¡é“"""
        # è¯„ä¼°æç¤ºæ¨¡æ¿
        self.evaluation_prompt = PromptTemplate(
            input_variables=["goals", "analysis", "summary", "format_instructions"],
            template="""
            è¯„ä¼°ä»¥ä¸‹ç ”ç©¶è®ºæ–‡æ‘˜è¦æ˜¯å¦æ»¡è¶³è®¾å®šçš„ç›®æ ‡:
            
            ç›®æ ‡: {goals}
            
            è®ºæ–‡åˆ†æ:
            {analysis}
            
            æ‘˜è¦:
            {summary}
            
            {format_instructions}
            
            è¯·å®¢è§‚è¯„ä¼°æ‘˜è¦è´¨é‡ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
                        """
        )

        # æ„å»ºè¯„ä¼°ç®¡é“
        self.evaluation_pipeline = (
                RunnablePassthrough.assign(
                    format_instructions=lambda _: self.evaluation_parser.get_format_instructions()
                )
                | self.evaluation_prompt
                | self.llm
                | RunnableLambda(lambda x: x.content)
                | self.evaluation_parser
        )

    def _build_improvement_pipeline(self):
        """æ„å»ºæ‘˜è¦æ”¹è¿›ç®¡é“"""
        # æ”¹è¿›æç¤ºæ¨¡æ¿
        self.improvement_prompt = PromptTemplate(
            input_variables=["summary", "feedback", "goals"],
            template="""
            æ ¹æ®ä»¥ä¸‹åé¦ˆæ”¹è¿›ç ”ç©¶è®ºæ–‡æ‘˜è¦:
            
            å½“å‰æ‘˜è¦:
            {summary}
            
            æ”¹è¿›åé¦ˆ:
            {feedback}
            
            ç›®æ ‡è¦æ±‚:
            {goals}
            
            è¯·æä¾›æ”¹è¿›åçš„æ‘˜è¦ï¼Œè¦æ±‚:
            1. ä¿æŒç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—
            2. å……åˆ†è€ƒè™‘åé¦ˆæ„è§
            3. ç¡®ä¿æ»¡è¶³æ‰€æœ‰ç›®æ ‡è¦æ±‚
            
            ç›´æ¥è¿”å›æ”¹è¿›åçš„æ‘˜è¦ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
                        """
        )

        # æ„å»ºæ”¹è¿›ç®¡é“
        self.improvement_pipeline = (
                self.improvement_prompt
                | self.llm
                | RunnableLambda(lambda x: x.content.strip())
        )

    def set_goals(self, goals: List[str]) -> None:
        """è®¾å®šåˆ†æç›®æ ‡"""
        self.goals = [g.strip() for g in goals]
        print(f"ğŸ¯ åˆ†æç›®æ ‡å·²è®¾å®š: {', '.join(self.goals)}")

    def analyze_paper(self, pdf_path: str) -> Dict[str, Any]:
        """åˆ†æPDFè®ºæ–‡çš„ä¸»æµç¨‹"""
        if not self.goals:
            raise ValueError("è¯·å…ˆä½¿ç”¨set_goals()æ–¹æ³•è®¾å®šåˆ†æç›®æ ‡")

        print(f"\nğŸš€ å¼€å§‹åˆ†æPDFè®ºæ–‡: {pdf_path}")
        print("=" * 60)

        # ç¬¬ä¸€æ­¥ï¼šè§£æPDF
        parse_result = self.pdf_parser.parser.invoke({"pdf_path": pdf_path})
        paper_text = parse_result["paper_text"]

        if not paper_text.strip():
            return {"success": False, "error": "æ— æ³•è§£æPDFå†…å®¹"}

        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ç®¡é“åˆ†æè®ºæ–‡
        print("ğŸ” å¼€å§‹åˆ†æè®ºæ–‡å†…å®¹...")
        analysis = self.analysis_pipeline.invoke({
            "paper_text": paper_text[:8000]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
        })

        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆåˆå§‹æ‘˜è¦
        print("ğŸ“ ç”Ÿæˆç ”ç©¶è®ºæ–‡æ‘˜è¦...")
        summary_pipeline = (
                PromptTemplate(
                    input_variables=["goals", "analysis"],
                    template="""
                    åŸºäºä»¥ä¸‹ç ”ç©¶è®ºæ–‡åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´æ˜äº†çš„æ‘˜è¦ï¼Œæ»¡è¶³ä»¥ä¸‹ç›®æ ‡:
                    {goals}
                    
                    è®ºæ–‡åˆ†æ:
                    {analysis}
                    
                    æ‘˜è¦åº”è¯¥:
                    1. ç®€æ˜æ‰¼è¦ï¼Œä¸è¶…è¿‡200å­—
                    2. çªå‡ºç ”ç©¶çš„ä¸»è¦è´¡çŒ®
                    3. ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€
                    4. é¿å…æŠ€æœ¯æœ¯è¯­è¿‡å¤š
                    
                    è¯·ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
                                    """
                )
                | self.llm
                | RunnableLambda(lambda x: x.content.strip())
        )

        current_summary = summary_pipeline.invoke({
            "goals": ", ".join(self.goals),
            "analysis": json.dumps(analysis, ensure_ascii=False, indent=2)
        })

        # ç¬¬å››æ­¥ï¼šè¿­ä»£è¯„ä¼°å’Œæ”¹è¿›
        iteration = 0
        final_evaluation = None

        while iteration < self.max_iterations:
            print(f"\n--- ğŸ” è¯„ä¼°è¿­ä»£ {iteration + 1}/{self.max_iterations} ---")

            # ä½¿ç”¨è¯„ä¼°ç®¡é“
            evaluation = self.evaluation_pipeline.invoke({
                "goals": ", ".join(self.goals),
                "analysis": json.dumps(analysis, ensure_ascii=False, indent=2),
                "summary": current_summary
            })

            meets_goals = evaluation.get("meets_goals", "").lower() == "æ˜¯"
            final_evaluation = evaluation

            print(f"âœ… è¯„ä¼°å®Œæˆ - æ»¡è¶³ç›®æ ‡: {evaluation.get('meets_goals', 'æœªçŸ¥')}")
            print(f"   å‡†ç¡®åº¦: {evaluation.get('accuracy_score', 'N/A')}/10")
            print(f"   æ¸…æ™°åº¦: {evaluation.get('clarity_score', 'N/A')}/10")
            print(f"   å®Œæ•´æ€§: {evaluation.get('completeness_score', 'N/A')}/10")

            if meets_goals:
                print(f"\nâœ… æ‘˜è¦æ»¡è¶³æ‰€æœ‰ç›®æ ‡ï¼Œåˆ†æå®Œæˆ (è¿­ä»£æ¬¡æ•°: {iteration + 1})")
                break

            # å¦‚æœä¸æ»¡è¶³ç›®æ ‡ä¸”æœªè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåˆ™æ”¹è¿›æ‘˜è¦
            if iteration < self.max_iterations - 1:
                print("\nğŸ› ï¸ æ‘˜è¦ä¸æ»¡è¶³ç›®æ ‡ï¼Œè¿›è¡Œæ”¹è¿›...")
                current_summary = self.improvement_pipeline.invoke({
                    "summary": current_summary,
                    "feedback": evaluation.get("feedback", "éœ€è¦æ”¹è¿›"),
                    "goals": ", ".join(self.goals)
                })
                iteration += 1
            else:
                print(f"\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({self.max_iterations})ï¼Œè¿”å›å½“å‰ç»“æœ")
                break

        # ä¿å­˜ç»“æœ
        self._save_results(pdf_path, analysis, current_summary, final_evaluation)

        return {
            "success": True,
            "analysis": analysis,
            "summary": current_summary,
            "evaluation": final_evaluation,
            "iterations": iteration + 1
        }

    def _save_results(self, pdf_path: str, analysis: Dict, summary: str, evaluation: Dict) -> None:
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        pdf_name = Path(pdf_path).stem
        output_dir = Path("analysis_results")
        output_dir.mkdir(exist_ok=True)

        # ä¿å­˜åˆ†ææŠ¥å‘Š
        report_path = output_dir / f"{pdf_name}_analysis_report.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("=== è®ºæ–‡åˆ†ææŠ¥å‘Š ===\n\n")
            f.write(f"è®ºæ–‡æ ‡é¢˜: {analysis.get('title', 'æœªçŸ¥')}\n")
            f.write(f"ä½œè€…: {analysis.get('authors', 'æœªçŸ¥')}\n\n")

            f.write("=== åˆ†æç»“æœ ===\n")
            f.write(json.dumps(analysis, ensure_ascii=False, indent=2))
            f.write("\n\n")

            f.write("=== æ‘˜è¦ ===\n")
            f.write(summary)
            f.write("\n\n")

            f.write("=== è¯„ä¼°ç»“æœ ===\n")
            f.write(json.dumps(evaluation, ensure_ascii=False, indent=2))

        print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ™ºèƒ½è®ºæ–‡åˆ†æå™¨
    analyzer = IntelligentPaperAnalyzer(max_iterations=3)

    # è®¾å®šåˆ†æç›®æ ‡
    analyzer.set_goals([
        "ç®€æ´æ˜äº†",
        "çªå‡ºç ”ç©¶è´¡çŒ®",
        "é€‚åˆéä¸“ä¸šè¯»è€…ç†è§£",
        "åŒ…å«å…³é”®å‘ç°",
        "ä¸è¶…è¿‡200å­—"
    ])

    # åˆ†æPDFè®ºæ–‡
    # è¯·å°†è·¯å¾„æ›¿æ¢ä¸ºå®é™…çš„PDFæ–‡ä»¶è·¯å¾„
    pdf_file_path = "åŸºäºå…³ç³»é©±åŠ¨å¤šæ¨¡æ€åµŒå…¥å¡‘å½¢çš„å›¾åƒæè¿°ç”Ÿæˆ.pdf"  # æ›¿æ¢ä¸ºä½ çš„PDFæ–‡ä»¶è·¯å¾„

    if os.path.exists(pdf_file_path):
        result = analyzer.analyze_paper(pdf_file_path)

        if result["success"]:
            print("\n" + "=" * 60)
            print("ğŸ“Š æœ€ç»ˆåˆ†æç»“æœ:")
            print("=" * 60)
            print(f"\nğŸ“ æœ€ç»ˆæ‘˜è¦:\n{result['summary']}")

            if "evaluation" in result and result["evaluation"]:
                eval_data = result["evaluation"]
                print(f"\nğŸ“ˆ è¯„ä¼°ç»“æœ:")
                print(f"   æ»¡è¶³ç›®æ ‡: {eval_data.get('meets_goals', 'æœªçŸ¥')}")
                print(f"   å‡†ç¡®åº¦: {eval_data.get('accuracy_score', 'N/A')}/10")
                print(f"   æ¸…æ™°åº¦: {eval_data.get('clarity_score', 'N/A')}/10")
                print(f"   å®Œæ•´æ€§: {eval_data.get('completeness_score', 'N/A')}/10")

            print(f"\nğŸ”„ è¿­ä»£æ¬¡æ•°: {result['iterations']}")
        else:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
    else:
        print(f"âš ï¸ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_file_path}")
        print("è¯·å°†PDFæ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œæˆ–ä¿®æ”¹pdf_file_pathå˜é‡æŒ‡å‘æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„")
```

## ä»£ç è§£æ

è¿™ä¸ªé¡¹ç›®æ˜¯â€œç›®æ ‡è®¾å®šå’Œç›‘æ§â€æ¨¡å¼ä¸€ä¸ªéå¸¸å‡ºè‰²çš„å®è·µæ¡ˆä¾‹ï¼Œå®ƒå·§å¦™åœ°ç»“åˆäº† PDF å¤„ç†ã€LangChain çš„ç®¡é“ï¼ˆLCELï¼‰å’Œ LLM çš„æ¨ç†èƒ½åŠ›ã€‚

### æ•´ä½“æ¶æ„

ä»£ç é‡‡ç”¨**æ¨¡å—åŒ–è®¾è®¡**ï¼Œå°†ä¸åŒçš„åŠŸèƒ½å°è£…åœ¨ç‹¬ç«‹çš„ç±»ä¸­ï¼Œæœ€åç”±ä¸€ä¸ªä¸»åè°ƒå™¨ï¼ˆ`IntelligentPaperAnalyzer`ï¼‰å°†å®ƒä»¬ä¸²è”èµ·æ¥ã€‚

1.  **`PDFParser`**ï¼šæ•°æ®è¾“å…¥å±‚ã€‚è´Ÿè´£ä»ç‰©ç†æ–‡ä»¶ï¼ˆPDFï¼‰ä¸­æå–åŸå§‹æ–‡æœ¬æ•°æ®ã€‚
2.  **`PaperAnalysisOutputParser` & `SummaryEvaluationOutputParser`**ï¼šæ•°æ®ç»“æ„åŒ–å±‚ã€‚è´Ÿè´£å°† LLM ç”Ÿæˆçš„éç»“æ„åŒ–æ–‡æœ¬ï¼Œè§£æä¸ºç¨‹åºå¯ä»¥ç†è§£å’Œä½¿ç”¨çš„ç»“æ„åŒ–æ•°æ®ï¼ˆå­—å…¸ï¼‰ã€‚
3.  **`IntelligentPaperAnalyzer`**ï¼šæ ¸å¿ƒå¤§è„‘ä¸æµç¨‹ç¼–æ’å±‚ã€‚å®ƒåŒ…å«äº†æ‰€æœ‰çš„ä¸šåŠ¡é€»è¾‘ã€ç›®æ ‡è®¾å®šã€å·¥ä½œæµæ„å»ºï¼ˆä½¿ç”¨ç®¡é“ç¬¦ï¼‰å’Œä¸»å¾ªç¯æ§åˆ¶ã€‚

---

### æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 1. `PDFParser` ç±»
```python
class PDFParser:
    def __init__(self):
        self.parser = RunnableLambda(self._parse_pdf)
```
*   **ç›®çš„**ï¼šå°† PDF æ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬ã€‚
*   **æŠ€æœ¯å®ç°**ï¼š
    *   ä½¿ç”¨ `pdfplumber` åº“ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæå– PDF æ–‡æœ¬å’Œè¡¨æ ¼çš„å¼ºå¤§å·¥å…·ã€‚
    *   **å…³é”®ç‚¹**ï¼šå®ƒæ²¡æœ‰ç›´æ¥æš´éœ²ä¸€ä¸ªè§£æå‡½æ•°ï¼Œè€Œæ˜¯å°† `_parse_pdf` æ–¹æ³•åŒ…è£…åœ¨ `RunnableLambda` ä¸­ã€‚è¿™æ˜¯ä¸ºäº†ä¸ LangChain çš„ç®¡é“ç¬¦ï¼ˆ`|`ï¼‰å…¼å®¹ã€‚LangChain çš„ç®¡é“è¦æ±‚æ¯ä¸ªç¯èŠ‚éƒ½æ˜¯ä¸€ä¸ª `Runnable` å¯¹è±¡ï¼Œ`RunnableLambda` å°±æ˜¯å°†æ™®é€š Python å‡½æ•°â€œå‡çº§â€ä¸º `Runnable` çš„ä¾¿æ·æ–¹å¼ã€‚

#### 2. `PaperAnalysisOutputParser` & `SummaryEvaluationOutputParser` ç±»
è¿™ä¸¤ä¸ªç±»ç»“æ„å‡ ä¹ç›¸åŒï¼Œæ˜¯ LangChain å¤„ç†ç»“æ„åŒ–è¾“å‡ºçš„æ ‡å‡†æ¨¡å¼ã€‚

```python
class PaperAnalysisOutputParser(BaseOutputParser[Dict[str, Any]]):
    analysis_schemas: ClassVar[List[ResponseSchema]] = [...]
    
    @property
    def _parser(self) -> StructuredOutputParser:
        return StructuredOutputParser.from_response_schemas(self.analysis_schemas)
    
    def parse(self, text: str) -> Dict[str, Any]:
        try:
            return self._parser.parse(text)
        except Exception as e:
            return {"raw_analysis": text}
```
*   **ç›®çš„**ï¼šç¡®ä¿ LLM çš„è¾“å‡ºæ˜¯å¯é¢„æµ‹çš„ã€ç»“æ„åŒ–çš„ JSON æ ¼å¼ï¼Œè€Œä¸æ˜¯éšæ„çš„æ–‡æœ¬ã€‚
*   **æŠ€æœ¯å®ç°**ï¼š
    *   **ç»§æ‰¿ `BaseOutputParser`**ï¼šè¿™æ˜¯ LangChain çš„æ ‡å‡†æ¥å£ã€‚
    *   **`ClassVar[List[ResponseSchema]]`**ï¼šå®šä¹‰äº†æœŸæœ›çš„ JSON ç»“æ„ã€‚ä¾‹å¦‚ï¼Œ`PaperAnalysisOutputParser` æœŸæœ› LLM è¿”å›åŒ…å« `title`ã€`authors`ã€`key_findings` ç­‰å­—æ®µçš„ JSONã€‚`ClassVar` è¡¨æ˜è¿™ä¸ªå˜é‡å±äºç±»ï¼Œè€Œä¸æ˜¯ç±»çš„å®ä¾‹ã€‚
    *   **`@property def _parser`**ï¼šä½¿ç”¨ `@property` è£…é¥°å™¨æ¥åˆ›å»º `StructuredOutputParser` çš„å®ä¾‹ã€‚è¿™æ˜¯ä¸€ç§å»¶è¿ŸåŠ è½½å’Œå°è£…çš„å¥½ä¹ æƒ¯ã€‚
    *   **`parse` æ–¹æ³•**ï¼šæ ¸å¿ƒæ–¹æ³•ï¼Œå®ƒè°ƒç”¨åº•å±‚çš„ `StructuredOutputParser` æ¥å°è¯•è§£ææ–‡æœ¬ã€‚é‡è¦çš„æ˜¯ï¼Œå®ƒåŒ…å«äº† `try...except` å—ï¼Œå¦‚æœè§£æå¤±è´¥ï¼ˆä¾‹å¦‚ LLM æ²¡æœ‰è¿”å›ä¸¥æ ¼çš„ JSONï¼‰ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªåŒ…å«åŸå§‹æ–‡æœ¬çš„å­—å…¸ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒï¼Œè¿™æ˜¯ä¸€ç§éå¸¸å¥å£®çš„è®¾è®¡ã€‚

#### 3. `IntelligentPaperAnalyzer` ç±»ï¼ˆæ ¸å¿ƒå¤§è„‘ï¼‰

è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£ç¼–æ’æ‰€æœ‰ç»„ä»¶å¹¶å®ç°â€œç›®æ ‡è®¾å®šå’Œç›‘æ§â€æ¨¡å¼ã€‚

##### a. åˆå§‹åŒ– (`__init__`)
```python
def __init__(self, api_key: str, max_iterations: int = 3):
    # ...
    self.llm = ChatDeepseek(...)
    self.pdf_parser = PDFParser()
    self.analysis_parser = PaperAnalysisOutputParser()
    # ...
    self._build_analysis_pipeline()
    self._build_evaluation_pipeline()
    self._build_improvement_pipeline()
```
*   **ç›®çš„**ï¼šåˆå§‹åŒ–æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶ï¼ˆLLMã€è§£æå™¨ï¼‰å¹¶é¢„æ„å»ºå·¥ä½œæµç®¡é“ã€‚
*   **è®¾è®¡äº®ç‚¹**ï¼šåœ¨åˆå§‹åŒ–æ—¶å°±æ„å»ºå¥½æ‰€æœ‰ç®¡é“ã€‚è¿™æ˜¯ä¸€ç§â€œå‡†å¤‡å°±ç»ªâ€çš„æ¨¡å¼ï¼Œå½“å®é™…ä»»åŠ¡å¼€å§‹æ—¶ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›é¢„æ„å»ºå¥½çš„ç®¡é“ï¼Œæé«˜äº†æ‰§è¡Œæ•ˆç‡ã€‚

##### b. ç®¡é“æ„å»º (`_build_..._pipeline`)

è¿™æ˜¯ LangChain è¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼‰å’Œç®¡é“ç¬¦ï¼ˆ`|`ï¼‰çš„ç²¾é«“æ‰€åœ¨ã€‚

```python
def _build_analysis_pipeline(self):
    self.analysis_pipeline = (
        RunnablePassthrough.assign(
            format_instructions=lambda _: self.analysis_parser.get_format_instructions()
        )
        | self.analysis_prompt
        | self.llm
        | RunnableLambda(lambda x: x.content)
        | self.analysis_parser
    )
```
*   **æ•°æ®æµè§£æ**ï¼š
    1.  **è¾“å…¥**ï¼šä¸€ä¸ªå­—å…¸ï¼Œå¦‚ `{"paper_text": "..."}`ã€‚
    2.  **`RunnablePassthrough.assign(...)`**ï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„å·¥å…·ã€‚å®ƒä¼šå°†åŸå§‹è¾“å…¥å­—å…¸åŸå°ä¸åŠ¨åœ°ä¼ é€’ç»™ä¸‹ä¸€æ­¥ï¼Œä½†åŒæ—¶ä¼šæ·»åŠ æˆ–æ›´æ–°ä¸€ä¸ªé”®ã€‚åœ¨è¿™é‡Œï¼Œå®ƒåŠ¨æ€åœ°æ·»åŠ äº† `format_instructions` é”®ï¼Œå…¶å€¼æ˜¯è§£æå™¨è¦æ±‚çš„ JSON æ ¼å¼è¯´æ˜ã€‚**è¿™å®ç°äº†ä¸Šä¸‹æ–‡çš„åŠ¨æ€æ³¨å…¥**ã€‚
    3.  **`| self.analysis_prompt`**ï¼šå°†ä¸Šä¸€æ­¥çš„å®Œæ•´å­—å…¸ï¼ˆ`{"paper_text": "...", "format_instructions": "..."}`ï¼‰ä¼ é€’ç»™ `PromptTemplate`ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ã€æ ¼å¼åŒ–çš„æç¤ºå­—ç¬¦ä¸²ã€‚
    4.  **`| self.llm`**ï¼šå°†æç¤ºå­—ç¬¦ä¸²å‘é€ç»™ DeepSeek LLMï¼Œè·å¾—ä¸€ä¸ª `AIMessage` å¯¹è±¡ã€‚
    5.  **`| RunnableLambda(lambda x: x.content)`**ï¼š`AIMessage` å¯¹è±¡é€šè¿‡ä¸€ä¸ªç®€å•çš„ Lambda å‡½æ•°ï¼Œåªæå–å…¶ `content` å±æ€§ï¼ˆå³ LLM è¿”å›çš„åŸå§‹æ–‡æœ¬ï¼‰ã€‚
    6.  **`| self.analysis_parser`**ï¼šå°†åŸå§‹æ–‡æœ¬ä¼ é€’ç»™æˆ‘ä»¬çš„è‡ªå®šä¹‰è§£æå™¨ï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªç»“æ„åŒ–çš„ Python å­—å…¸ã€‚

*   **è¯„ä¼°ç®¡é“å’Œæ”¹è¿›ç®¡é“**ä¹Ÿéµå¾ªåŒæ ·çš„æ¨¡å¼ï¼Œåªæ˜¯è¾“å…¥çš„æç¤ºå’Œæœ€ç»ˆçš„è§£æå™¨ä¸åŒã€‚

##### c. ä¸»æµç¨‹ (`analyze_paper`)

è¿™æ˜¯æ•´ä¸ª Agent çš„â€œè¡ŒåŠ¨-ç›‘æ§-åé¦ˆâ€å¾ªç¯çš„ä½“ç°ã€‚

```python
def analyze_paper(self, pdf_path: str) -> Dict[str, Any]:
    # 1. ç›®æ ‡æ£€æŸ¥
    if not self.goals:
        raise ValueError(...)
    
    # 2. æ•°æ®å‡†å¤‡
    parse_result = self.pdf_parser.parser.invoke({"pdf_path": pdf_path})
    paper_text = parse_result["paper_text"]
    
    # 3. åˆå§‹åˆ†æä¸ç”Ÿæˆ
    analysis = self.analysis_pipeline.invoke({"paper_text": paper_text[:8000]})
    current_summary = summary_pipeline.invoke(...)
    
    # 4. æ ¸å¿ƒç›‘æ§ä¸è¿­ä»£å¾ªç¯
    iteration = 0
    while iteration < self.max_iterations:
        # --- ç›‘æ§ ---
        evaluation = self.evaluation_pipeline.invoke({
            "goals": ", ".join(self.goals),
            "analysis": json.dumps(analysis, ...),
            "summary": current_summary
        })
        meets_goals = evaluation.get("meets_goals", "").lower() == "æ˜¯"
        
        # --- å†³ç­– ---
        if meets_goals:
            print("âœ… æ‘˜è¦æ»¡è¶³æ‰€æœ‰ç›®æ ‡ï¼Œåˆ†æå®Œæˆ")
            break
        
        # --- åé¦ˆä¸è¡ŒåŠ¨ ---
        if iteration < self.max_iterations - 1:
            current_summary = self.improvement_pipeline.invoke({
                "summary": current_summary,
                "feedback": evaluation.get("feedback", "éœ€è¦æ”¹è¿›"), # å…³é”®åé¦ˆ
                "goals": ", ".join(self.goals)
            })
            iteration += 1
        else:
            break
            
    # 5. ç»“æœæŒä¹…åŒ–
    self._save_results(...)
    return {...}
```

*   **æµç¨‹åˆ†è§£**ï¼š
    1.  **ç›®æ ‡è®¾å®š**ï¼šåœ¨å¾ªç¯å¼€å§‹å‰ï¼Œé€šè¿‡ `set_goals` æ–¹æ³•è®¾å®šï¼Œå¹¶åœ¨å¾ªç¯ä¸­åå¤ä½¿ç”¨ã€‚
    2.  **åˆå§‹è¡ŒåŠ¨**ï¼šå…ˆè¿›è¡Œä¸€æ¬¡æ€§çš„åˆ†æå’Œæ‘˜è¦ç”Ÿæˆã€‚
    3.  **`while` å¾ªç¯ï¼ˆç›‘æ§æ ¸å¿ƒï¼‰**ï¼š
        *   **ç›‘æ§**ï¼šè°ƒç”¨ `evaluation_pipeline`ï¼Œè®© LLM å……å½“â€œè£åˆ¤â€ï¼Œæ ¹æ®ç›®æ ‡è¯„ä¼°å½“å‰çš„ `summary`ã€‚
        *   **å†³ç­–**ï¼šæ£€æŸ¥è¯„ä¼°ç»“æœä¸­çš„ `meets_goals` å­—æ®µã€‚è¿™æ˜¯â€œåˆ¤æ–­è‡ªèº«æ˜¯å¦çœŸæ­£æˆåŠŸâ€çš„å…³é”®ä¸€æ­¥ã€‚
        *   **åé¦ˆå¾ªç¯**ï¼šå¦‚æœç›®æ ‡æœªè¾¾æˆï¼Œåˆ™è°ƒç”¨ `improvement_pipeline`ã€‚**æœ€å…³é”®çš„æ˜¯**ï¼Œå®ƒå°†ä¸Šä¸€æ­¥è¯„ä¼°ä¸­äº§ç”Ÿçš„ `feedback` ä½œä¸ºè¾“å…¥ä¼ é€’ç»™æ”¹è¿›ç®¡é“ã€‚è¿™å½¢æˆäº†ä¸€ä¸ª**é—­ç¯çš„ã€åŸºäºåé¦ˆçš„è‡ªæˆ‘ä¿®æ­£æœºåˆ¶**ã€‚
    4.  **ç»ˆæ­¢æ¡ä»¶**ï¼šå¾ªç¯åœ¨ `meets_goals` ä¸º `True` æˆ–è¾¾åˆ° `max_iterations` æ—¶ç»ˆæ­¢ï¼Œé˜²æ­¢æ— é™å¾ªç¯ã€‚
    5.  **ç»“æœä¿å­˜**ï¼šå°†æœ€ç»ˆçš„åˆ†æã€æ‘˜è¦å’Œè¯„ä¼°ç»“æœä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¾¿äºç”¨æˆ·æŸ¥çœ‹å’Œå®¡è®¡ã€‚

---

### æ€»ç»“

è¿™ä¸ªä»£ç æ¡ˆä¾‹ä¹‹æ‰€ä»¥ä¼˜ç§€ï¼Œåœ¨äºå®ƒï¼š

1.  **å®Œç¾è¯ é‡Šäº†è®¾è®¡æ¨¡å¼**ï¼šå®ƒä¸æ˜¯ç©ºæ´çš„ç†è®ºï¼Œè€Œæ˜¯å°†â€œç›®æ ‡è®¾å®šâ€å’Œâ€œç›‘æ§â€æ¨¡å¼å…·ä½“åŒ–ä¸ºäº†å¯æ‰§è¡Œçš„ä»£ç é€»è¾‘ã€‚
2.  **æ¶æ„æ¸…æ™°ã€æ¨¡å—åŒ–**ï¼šæ¯ä¸ªç±»éƒ½æœ‰å•ä¸€èŒè´£ï¼Œä½¿å¾—ä»£ç æ˜“äºç†è§£ã€æµ‹è¯•å’Œç»´æŠ¤ã€‚
3.  **å……åˆ†åˆ©ç”¨äº†ç°ä»£æ¡†æ¶**ï¼šå®ƒå±•ç¤ºäº† LangChain LCEL çš„å¼ºå¤§ä¹‹å¤„ï¼Œç”¨å£°æ˜å¼çš„ç®¡é“ç¬¦æ„å»ºäº†å¤æ‚çš„æ•°æ®æµï¼Œä»£ç æ—¢ç®€æ´åˆå¯Œæœ‰è¡¨ç°åŠ›ã€‚
4.  **å¥å£®ä¸”å®ç”¨**ï¼šåŒ…å«äº†é”™è¯¯å¤„ç†ï¼ˆå¦‚è§£æå¤±è´¥ï¼‰ã€é˜²å¾¡æ€§ç¼–ç¨‹ï¼ˆå¦‚é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼‰ã€ç»“æœæŒä¹…åŒ–ç­‰ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæ¥è¿‘ç”Ÿäº§çº§åˆ«çš„åº”ç”¨åŸå‹ã€‚
5.  **æ™ºèƒ½åŒ–é—­ç¯**ï¼šé€šè¿‡è®© LLM åŒæ—¶æ‰®æ¼”â€œæ‰§è¡Œè€…â€å’Œâ€œè¯„åˆ¤è€…â€çš„è§’è‰²ï¼Œæ„å»ºäº†ä¸€ä¸ªæ™ºèƒ½çš„ã€èƒ½å¤Ÿè‡ªæˆ‘ä¼˜åŒ–çš„é—­ç¯ç³»ç»Ÿï¼Œè¿™æ­£æ˜¯é«˜çº§ AI Agent çš„æ ¸å¿ƒç‰¹å¾ã€‚

## å››.langgraphå®ç°
```python
import os
import json
import re
from typing import List, Dict, Any, Optional, TypedDict, Literal
from pathlib import Path

# PDFå¤„ç†åº“
import pdfplumber

# LangChain & LangGraph ç»„ä»¶
from langchain_classic.output_parsers import ResponseSchema, StructuredOutputParser

# LangGraph æ ¸å¿ƒç»„ä»¶
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.prompts import PromptTemplate
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from init_client import init_llm

llm = init_llm(0.1)
# --- 1. å®šä¹‰ Agent çš„çŠ¶æ€ ---
class AgentState(TypedDict):
    """å®šä¹‰åœ¨æ•´ä¸ªå›¾ä¸­æµè½¬çš„çŠ¶æ€"""
    pdf_path: str
    paper_text: str
    goals: List[str]
    analysis: Dict[str, Any]
    current_summary: str
    evaluation: Dict[str, Any]
    iterations: int
    max_iterations: int
    final_result: Optional[Dict[str, Any]]
    error_message: Optional[str]


# --- 2. å®šä¹‰å›¾çš„èŠ‚ç‚¹ (æ¯ä¸ªèŠ‚ç‚¹æ˜¯ä¸€ä¸ªæ‰§è¡Œæ­¥éª¤) ---

def parse_pdf_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹1: è§£æPDFæ–‡ä»¶"""
    print("ğŸ” èŠ‚ç‚¹: è§£æPDFæ–‡ä»¶...")
    pdf_path = state["pdf_path"]
    if not os.path.exists(pdf_path):
        return {"error_message": f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"}

    try:
        with pdfplumber.open(pdf_path) as pdf:
            text_content = []
            max_pages = min(len(pdf.pages), 10)
            for i in range(max_pages):
                page = pdf.pages[i]
                text = page.extract_text()
                if text:
                    text_content.append(text)
            paper_text = "\n\n".join(text_content)
            paper_text = re.sub(r'\s+', ' ', paper_text)
            print(f"âœ… PDFè§£æå®Œæˆï¼Œå…±æå– {len(paper_text)} å­—ç¬¦")
            return {"paper_text": paper_text}
    except Exception as e:
        return {"error_message": f"PDFè§£æå¤±è´¥: {e}"}


def analyze_paper_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹2: åˆ†æè®ºæ–‡å†…å®¹"""
    print("ğŸ” èŠ‚ç‚¹: åˆ†æè®ºæ–‡å†…å®¹...")
    paper_text = state["paper_text"]

    analysis_schemas = [
        ResponseSchema(name="title", description="è®ºæ–‡æ ‡é¢˜"),
        ResponseSchema(name="authors", description="è®ºæ–‡ä½œè€…åˆ—è¡¨"),
        ResponseSchema(name="abstract", description="è®ºæ–‡æ‘˜è¦"),
        ResponseSchema(name="key_findings", description="ä¸»è¦å‘ç°ï¼Œä»¥åˆ—è¡¨å½¢å¼å‘ˆç°"),
        ResponseSchema(name="methodology", description="ç ”ç©¶æ–¹æ³•ç®€è¿°"),
    ]
    analysis_parser = StructuredOutputParser.from_response_schemas(analysis_schemas)

    prompt = PromptTemplate(
        input_variables=["paper_text", "format_instructions"],
        template="""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹ç ”ç©¶è®ºæ–‡ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ã€‚
{format_instructions}

è®ºæ–‡å†…å®¹:
{paper_text}

è¯·ç¡®ä¿æå–çš„ä¿¡æ¯å‡†ç¡®å®Œæ•´ã€‚
        """
    )
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶åˆ†æä¸“å®¶ã€‚"),
        HumanMessage(content=prompt.format(
            paper_text=paper_text[:8000],  # é™åˆ¶é•¿åº¦
            format_instructions=analysis_parser.get_format_instructions()
        ))
    ]
    response = llm.invoke(messages)
    analysis = analysis_parser.parse(response.content)

    print("âœ… è®ºæ–‡åˆ†æå®Œæˆ")
    return {"analysis": analysis}


def generate_summary_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹3: ç”Ÿæˆåˆå§‹æ‘˜è¦"""
    print("ğŸ” èŠ‚ç‚¹: ç”Ÿæˆåˆå§‹æ‘˜è¦...")
    analysis = state["analysis"]
    goals = state["goals"]

    prompt = PromptTemplate(
        input_variables=["goals", "analysis"],
        template="""
åŸºäºä»¥ä¸‹ç ”ç©¶è®ºæ–‡åˆ†æï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´æ˜äº†çš„æ‘˜è¦ï¼Œæ»¡è¶³ä»¥ä¸‹ç›®æ ‡:
{goals}

è®ºæ–‡åˆ†æ:
{analysis}

æ‘˜è¦åº”è¯¥:
1. ç®€æ˜æ‰¼è¦ï¼Œä¸è¶…è¿‡200å­—
2. çªå‡ºç ”ç©¶çš„ä¸»è¦è´¡çŒ®
3. ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€
4. é¿å…æŠ€æœ¯æœ¯è¯­è¿‡å¤š

è¯·ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
        """
    )

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯å†™ä½œä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚ç ”ç©¶è½¬åŒ–ä¸ºç®€æ´æ˜“æ‡‚çš„æ‘˜è¦ã€‚"),
        HumanMessage(content=prompt.format(
            goals=", ".join(goals),
            analysis=json.dumps(analysis, ensure_ascii=False, indent=2)
        ))
    ]
    response = llm.invoke(messages)
    summary = response.content.strip()

    print("âœ… åˆå§‹æ‘˜è¦ç”Ÿæˆå®Œæˆ")
    return {"current_summary": summary, "iterations": 1}


def evaluate_summary_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹4: è¯„ä¼°æ‘˜è¦è´¨é‡"""
    print("ğŸ” èŠ‚ç‚¹: è¯„ä¼°æ‘˜è¦è´¨é‡...")
    summary = state["current_summary"]
    analysis = state["analysis"]
    goals = state["goals"]

    eval_schemas = [
        ResponseSchema(name="meets_goals", description="æ‘˜è¦æ˜¯å¦æ»¡è¶³æ‰€æœ‰è®¾å®šç›®æ ‡ï¼Œå›ç­”'æ˜¯'æˆ–'å¦'"),
        ResponseSchema(name="accuracy_score", description="æ‘˜è¦å‡†ç¡®åº¦è¯„åˆ†ï¼Œ1-10"),
        ResponseSchema(name="clarity_score", description="æ‘˜è¦æ¸…æ™°åº¦è¯„åˆ†ï¼Œ1-10"),
        ResponseSchema(name="feedback", description="æ”¹è¿›å»ºè®®ï¼Œå¦‚æœä¸æ»¡è¶³ç›®æ ‡"),
    ]
    eval_parser = StructuredOutputParser.from_response_schemas(eval_schemas)

    prompt = PromptTemplate(
        input_variables=["goals", "analysis", "summary", "format_instructions"],
        template="""
è¯„ä¼°ä»¥ä¸‹ç ”ç©¶è®ºæ–‡æ‘˜è¦æ˜¯å¦æ»¡è¶³è®¾å®šçš„ç›®æ ‡:

ç›®æ ‡: {goals}

è®ºæ–‡åˆ†æ:
{analysis}

æ‘˜è¦:
{summary}

{format_instructions}

è¯·å®¢è§‚è¯„ä¼°æ‘˜è¦è´¨é‡ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
        """
    )

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å­¦æœ¯è¯„ä¼°ä¸“å®¶ï¼Œæ“…é•¿è¯„ä¼°ç ”ç©¶æ‘˜è¦çš„è´¨é‡ã€‚"),
        HumanMessage(content=prompt.format(
            goals=", ".join(goals),
            analysis=json.dumps(analysis, ensure_ascii=False, indent=2),
            summary=summary,
            format_instructions=eval_parser.get_format_instructions()
        ))
    ]
    response = llm.invoke(messages)
    evaluation = eval_parser.parse(response.content)

    print(f"âœ… è¯„ä¼°å®Œæˆ - æ»¡è¶³ç›®æ ‡: {evaluation.get('meets_goals', 'æœªçŸ¥')}")
    return {"evaluation": evaluation}


def improve_summary_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹5: æ”¹è¿›æ‘˜è¦"""
    print("ğŸ” èŠ‚ç‚¹: æ”¹è¿›æ‘˜è¦...")
    summary = state["current_summary"]
    feedback = state["evaluation"].get("feedback", "éœ€è¦æ”¹è¿›")
    goals = state["goals"]

    prompt = PromptTemplate(
        input_variables=["summary", "feedback", "goals"],
        template="""
æ ¹æ®ä»¥ä¸‹åé¦ˆæ”¹è¿›ç ”ç©¶è®ºæ–‡æ‘˜è¦:

å½“å‰æ‘˜è¦:
{summary}

æ”¹è¿›åé¦ˆ:
{feedback}

ç›®æ ‡è¦æ±‚:
{goals}

è¯·æä¾›æ”¹è¿›åçš„æ‘˜è¦ï¼Œè¦æ±‚:
1. ä¿æŒç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—
2. å……åˆ†è€ƒè™‘åé¦ˆæ„è§
3. ç¡®ä¿æ»¡è¶³æ‰€æœ‰ç›®æ ‡è¦æ±‚

ç›´æ¥è¿”å›æ”¹è¿›åçš„æ‘˜è¦ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
        """
    )

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯å†™ä½œæ”¹è¿›ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®åé¦ˆä¼˜åŒ–ç ”ç©¶æ‘˜è¦ã€‚"),
        HumanMessage(content=prompt.format(
            summary=summary,
            feedback=feedback,
            goals=", ".join(goals)
        ))
    ]
    response = llm.invoke(messages)
    improved_summary = response.content.strip()

    print("âœ… æ‘˜è¦æ”¹è¿›å®Œæˆ")
    # å¢åŠ è¿­ä»£æ¬¡æ•°
    return {"current_summary": improved_summary, "iterations": state["iterations"] + 1}


def save_results_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹6: ä¿å­˜æœ€ç»ˆç»“æœ"""
    print("ğŸ” èŠ‚ç‚¹: ä¿å­˜æœ€ç»ˆç»“æœ...")
    pdf_path = state["pdf_path"]
    analysis = state["analysis"]
    summary = state["current_summary"]
    evaluation = state["evaluation"]

    pdf_name = Path(pdf_path).stem
    output_dir = Path("analysis_results_langgraph")
    output_dir.mkdir(exist_ok=True)

    report_path = output_dir / f"{pdf_name}_analysis_report.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("=== è®ºæ–‡åˆ†ææŠ¥å‘Š (LangGraphç‰ˆæœ¬) ===\n\n")
        f.write(f"è®ºæ–‡æ ‡é¢˜: {analysis.get('title', 'æœªçŸ¥')}\n")
        f.write(f"ä½œè€…: {analysis.get('authors', 'æœªçŸ¥')}\n\n")
        f.write("=== åˆ†æç»“æœ ===\n")
        f.write(json.dumps(analysis, ensure_ascii=False, indent=2))
        f.write("\n\n=== æœ€ç»ˆæ‘˜è¦ ===\n")
        f.write(summary)
        f.write("\n\n=== æœ€ç»ˆè¯„ä¼° ===\n")
        f.write(json.dumps(evaluation, ensure_ascii=False, indent=2))

    print(f"ğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    return {"final_result": {"analysis": analysis, "summary": summary, "evaluation": evaluation}}


# --- 3. å®šä¹‰å†³ç­–é€»è¾‘ (å†³å®šä¸‹ä¸€æ­¥èµ°å‘å“ªä¸ªèŠ‚ç‚¹) ---

def should_continue(state: AgentState) -> Literal["improve_summary", "save_results", "end"]:
    """å†³ç­–å‡½æ•°ï¼šæ ¹æ®è¯„ä¼°ç»“æœå’Œè¿­ä»£æ¬¡æ•°å†³å®šä¸‹ä¸€æ­¥"""
    evaluation = state["evaluation"]
    iterations = state["iterations"]
    max_iterations = state["max_iterations"]

    if evaluation.get("meets_goals", "").lower() == "æ˜¯":
        print("âœ… å†³ç­–: ç›®æ ‡å·²æ»¡è¶³ï¼Œå‡†å¤‡ä¿å­˜ç»“æœã€‚")
        return "save_results"
    elif iterations < max_iterations:
        print(f"ğŸ”„ å†³ç­–: ç›®æ ‡æœªæ»¡è¶³ï¼Œä½†æœªè¾¾æœ€å¤§è¿­ä»£æ¬¡æ•°({iterations}/{max_iterations})ï¼Œç»§ç»­æ”¹è¿›ã€‚")
        return "improve_summary"
    else:
        print(f"âš ï¸ å†³ç­–: å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°({max_iterations})ï¼Œç»“æŸæµç¨‹ã€‚")
        return "end"


# --- 4. æ„å»ºå’Œç¼–è¯‘å›¾ ---

def build_graph():
    """æ„å»ºLangGraphå·¥ä½œæµå›¾"""
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("parse_pdf", parse_pdf_node)
    workflow.add_node("analyze_paper", analyze_paper_node)
    workflow.add_node("generate_summary", generate_summary_node)
    workflow.add_node("evaluate_summary", evaluate_summary_node)
    workflow.add_node("improve_summary", improve_summary_node)
    workflow.add_node("save_results", save_results_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("parse_pdf")

    # æ·»åŠ çº¿æ€§è¾¹
    workflow.add_edge("parse_pdf", "analyze_paper")
    workflow.add_edge("analyze_paper", "generate_summary")
    workflow.add_edge("generate_summary", "evaluate_summary")

    # æ·»åŠ æ¡ä»¶è¾¹ï¼šä»è¯„ä¼°èŠ‚ç‚¹åˆ°å†³ç­–
    workflow.add_conditional_edges(
        "evaluate_summary",
        should_continue,
        {
            "improve_summary": "improve_summary",
            "save_results": "save_results",
            "end": END
        }
    )

    # æ·»åŠ å¾ªç¯è¾¹ï¼šä»æ”¹è¿›èŠ‚ç‚¹å›åˆ°è¯„ä¼°èŠ‚ç‚¹
    workflow.add_edge("improve_summary", "evaluate_summary")

    # æ·»åŠ ç»“æŸè¾¹
    workflow.add_edge("save_results", END)

    # ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹æ¥ä¿å­˜çŠ¶æ€ï¼ˆå¯é€‰ï¼Œä½†å¯¹äºæŒä¹…åŒ–å’Œè°ƒè¯•å¾ˆæœ‰ç”¨ï¼‰
    memory = MemorySaver()

    # ç¼–è¯‘å›¾
    app = workflow.compile(checkpointer=memory)
    return app


# --- 5. å°è£…æˆä¸»ç±» ---

class LangGraphPaperAnalyzer:
    def __init__(self, max_iterations: int = 3):
        self.max_iterations = max_iterations
        self.app = build_graph()
        # å¯é€‰ï¼šå¯è§†åŒ–å›¾çš„ç»“æ„
        self.app.get_graph().print_ascii()

    def analyze(self, pdf_path: str, goals: List[str]) -> Dict[str, Any]:
        """å¯åŠ¨åˆ†ææµç¨‹"""
        print(f"\nğŸš€ å¯åŠ¨ LangGraph è®ºæ–‡åˆ†æå™¨...")
        print("=" * 60)

        initial_state = {
            "pdf_path": pdf_path,
            "paper_text": "",
            "goals": goals,
            "analysis": {},
            "current_summary": "",
            "evaluation": {},
            "iterations": 0,
            "max_iterations": self.max_iterations,
            "final_result": None,
            "error_message": None
        }

        # ä½¿ç”¨ thread_id æ¥è·Ÿè¸ªç‰¹å®šçš„å¯¹è¯/è¿è¡Œ
        config = {"configurable": {"thread_id": "paper-analysis-1"}}

        # è¿è¡Œå›¾ç›´åˆ°ç»“æŸ
        final_state = self.app.invoke(initial_state, config=config)

        if final_state.get("error_message"):
            print(f"\nâŒ æµç¨‹å‡ºé”™: {final_state['error_message']}")
            return {"success": False, "error": final_state["error_message"]}

        if final_state.get("final_result"):
            print("\nâœ… åˆ†ææµç¨‹æˆåŠŸå®Œæˆï¼")
            return {"success": True, "result": final_state["final_result"]}
        else:
            print("\nâš ï¸ æµç¨‹ç»“æŸï¼Œä½†æœªè¾¾åˆ°ç›®æ ‡ã€‚")
            return {"success": False, "result": final_state, "message": "æœªåœ¨æœ€å¤§è¿­ä»£æ¬¡æ•°å†…è¾¾æˆç›®æ ‡"}


# --- 6. ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå™¨
    analyzer = LangGraphPaperAnalyzer(max_iterations=3)

    # è®¾å®šç›®æ ‡
    goals = [
        "ç®€æ´æ˜äº†",
        "çªå‡ºç ”ç©¶è´¡çŒ®",
        "é€‚åˆéä¸“ä¸šè¯»è€…ç†è§£",
        "åŒ…å«å…³é”®å‘ç°",
        "ä¸è¶…è¿‡200å­—"
    ]

    # åˆ†æPDFè®ºæ–‡
    pdf_file_path = "åŸºäºå…³ç³»é©±åŠ¨å¤šæ¨¡æ€åµŒå…¥å¡‘å½¢çš„å›¾åƒæè¿°ç”Ÿæˆ.pdf"  # æ›¿æ¢ä¸ºä½ çš„PDFæ–‡ä»¶è·¯å¾„

    if os.path.exists(pdf_file_path):
        result = analyzer.analyze(pdf_file_path, goals)

        if result["success"]:
            print("\n" + "=" * 60)
            print("ğŸ“Š æœ€ç»ˆåˆ†æç»“æœ:")
            print("=" * 60)
            final_data = result["result"]
            print(f"\nğŸ“ æœ€ç»ˆæ‘˜è¦:\n{final_data['summary']}")

            eval_data = final_data['evaluation']
            print(f"\nğŸ“ˆ æœ€ç»ˆè¯„ä¼°:")
            print(f"   æ»¡è¶³ç›®æ ‡: {eval_data.get('meets_goals', 'æœªçŸ¥')}")
            print(f"   å‡†ç¡®åº¦: {eval_data.get('accuracy_score', 'N/A')}/10")
            print(f"   æ¸…æ™°åº¦: {eval_data.get('clarity_score', 'N/A')}/10")
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥æˆ–æœªå®Œæˆ: {result.get('error', result.get('message'))}")
    else:
        print(f"âš ï¸ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_file_path}")
```

## ä»£ç è§£æ

---

#### 1. çŠ¶æ€ï¼š`AgentState` - æ¨¡å¼çš„åŸºçŸ³

```python
class AgentState(TypedDict):
    """å®šä¹‰åœ¨æ•´ä¸ªå›¾ä¸­æµè½¬çš„çŠ¶æ€"""
    pdf_path: str
    paper_text: str
    goals: List[str]  # <-- ç›®æ ‡åœ¨è¿™é‡Œ
    analysis: Dict[str, Any]
    current_summary: str
    evaluation: Dict[str, Any]  # <-- ç›‘æ§ç»“æœåœ¨è¿™é‡Œ
    iterations: int
    max_iterations: int
    # ...
```

`AgentState` æ˜¯æ•´ä¸ªç³»ç»Ÿçš„â€œå…±äº«è®°å¿†â€æˆ–â€œå·¥ä½œæ¿â€ã€‚å®ƒä¸æ˜¯ç®€å•çš„æ•°æ®ä¼ é€’ï¼Œè€Œæ˜¯**æ‰¿è½½äº† Agent åœ¨æ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ä¸­çš„æ‰€æœ‰ä¸Šä¸‹æ–‡**ã€‚

*   **ç›®æ ‡è®¾å®š**ï¼š`goals: List[str]` å­—æ®µè¢«æ˜ç¡®å®šä¹‰åœ¨çŠ¶æ€ä¸­ï¼Œæ„å‘³ç€â€œç›®æ ‡â€æ˜¯ Agent å†³ç­–çš„æ ¸å¿ƒä¾æ®ï¼Œè´¯ç©¿å§‹ç»ˆã€‚
*   **ç›‘æ§**ï¼š`evaluation: Dict[str, Any]` å­—æ®µç”¨äºå­˜å‚¨ç›‘æ§çš„ç»“æœï¼Œè¿™æ˜¯ Agent åˆ¤æ–­è‡ªå·±æ˜¯å¦æˆåŠŸçš„ä¾æ®ã€‚

#### 2. ç›®æ ‡è®¾å®šï¼šä»å¤–éƒ¨è¾“å…¥åˆ°å†…éƒ¨é©±åŠ¨

```python
# --- 6. ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == "__main__":
    # è®¾å®šç›®æ ‡
    goals = [
        "ç®€æ´æ˜äº†",
        "çªå‡ºç ”ç©¶è´¡çŒ®",
        "é€‚åˆéä¸“ä¸šè¯»è€…ç†è§£",
        "åŒ…å«å…³é”®å‘ç°",
        "ä¸è¶…è¿‡200å­—"
    ]
    # ...
    result = analyzer.analyze(pdf_file_path, goals)
```

*   **æ˜ç¡®çš„èµ·ç‚¹**ï¼šç›®æ ‡åœ¨è¿™é‡Œè¢«æ¸…æ™°åœ°ã€å¯é‡åŒ–åœ°å®šä¹‰ã€‚å®ƒä»¬ä¸æ˜¯æ¨¡ç³Šçš„æŒ‡ä»¤ï¼Œè€Œæ˜¯å¯ä»¥è¢« LLM ç†è§£å’Œè¯„åˆ¤çš„å…·ä½“æ ‡å‡†ã€‚
*   **æ³¨å…¥çŠ¶æ€**ï¼šåœ¨ `analyze` æ–¹æ³•ä¸­ï¼Œè¿™äº› `goals` è¢«æ”¾å…¥ `initial_state`ï¼Œæˆä¸º Agent çŠ¶æ€æœºå¯åŠ¨çš„åˆå§‹æ¡ä»¶ä¹‹ä¸€ã€‚ä»æ­¤åˆ»èµ·ï¼Œç›®æ ‡ä¸å†æ˜¯å¤–éƒ¨å˜é‡ï¼Œè€Œæ˜¯é©±åŠ¨ Agent å†…éƒ¨å†³ç­–çš„**å†…åœ¨é©±åŠ¨åŠ›**ã€‚

#### 3. ç›‘æ§ï¼š`evaluate_summary_node` - æ¨¡å¼çš„æ ¸å¿ƒ

è¿™æ˜¯æ•´ä¸ªæ¨¡å¼æœ€å…³é”®çš„èŠ‚ç‚¹ï¼Œå®ƒæ‰®æ¼”äº†â€œè‡ªæˆ‘åæ€â€å’Œâ€œè¿›åº¦æ£€æŸ¥â€çš„è§’è‰²ã€‚

```python
def evaluate_summary_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹4: è¯„ä¼°æ‘˜è¦è´¨é‡"""
    # ...
    summary = state["current_summary"]  # å½“å‰çš„äº§å‡º
    analysis = state["analysis"]
    goals = state["goals"]              # æœ€åˆçš„ç›®æ ‡
    
    # ...
    # è®© LLM å……å½“â€œè£åˆ¤â€ï¼Œæ ¹æ®â€œç›®æ ‡â€è¯„ä¼°â€œäº§å‡ºâ€
    response = llm.invoke(messages)
    evaluation = eval_parser.parse(response.content) # è§£æä¸ºç»“æ„åŒ–ç»“æœ
    
    print(f"âœ… è¯„ä¼°å®Œæˆ - æ»¡è¶³ç›®æ ‡: {evaluation.get('meets_goals', 'æœªçŸ¥')}")
    return {"evaluation": evaluation} # å°†ç›‘æ§ç»“æœæ›´æ–°åˆ°çŠ¶æ€ä¸­
```

*   **å¯¹æ¯”åˆ†æ**ï¼šè¯¥èŠ‚ç‚¹çš„æ ¸å¿ƒé€»è¾‘æ˜¯**å°†â€œå½“å‰çŠ¶æ€â€ä¸â€œç›®æ ‡çŠ¶æ€â€è¿›è¡Œå¯¹æ¯”**ã€‚å®ƒæ¥æ”¶ `current_summary`ï¼ˆæˆ‘ä»¬ç°åœ¨åœ¨å“ªï¼‰å’Œ `goals`ï¼ˆæˆ‘ä»¬åº”è¯¥åœ¨å“ªï¼‰ã€‚
*   **é‡åŒ–ç›‘æ§**ï¼šå®ƒæ²¡æœ‰ç®€å•åœ°å›ç­”â€œå¥½/åâ€ï¼Œè€Œæ˜¯ç”Ÿæˆäº†ä¸€ä¸ªç»“æ„åŒ–çš„ `evaluation` å­—å…¸ï¼ŒåŒ…å«ï¼š
    *   `meets_goals`ï¼šä¸€ä¸ªæ˜ç¡®çš„å¸ƒå°”å€¼ï¼Œç›´æ¥å›ç­”â€œæˆ‘æˆåŠŸäº†å—ï¼Ÿâ€
    *   `accuracy_score`, `clarity_score`ï¼šé‡åŒ–æŒ‡æ ‡ï¼Œæä¾›äº†æ›´ç»†ç²’åº¦çš„è¿›åº¦ä¿¡æ¯ã€‚
    *   `feedback`ï¼šå¦‚æœæœªæˆåŠŸï¼Œæä¾›äº†å…·ä½“çš„ã€å¯æ“ä½œçš„â€œå·®è·åˆ†æâ€å’Œæ”¹è¿›å»ºè®®ã€‚
*   **çŠ¶æ€æ›´æ–°**ï¼šç›‘æ§çš„ç»“æœè¢«å†™å›åˆ° `AgentState` ä¸­ï¼Œä¾›ä¸‹ä¸€ä¸ªå†³ç­–èŠ‚ç‚¹ä½¿ç”¨ã€‚

#### 4. å†³ç­–ä¸å¾ªç¯ï¼š`should_continue` å’Œ `add_conditional_edges` - æ¨¡å¼çš„é—­ç¯

è¿™æ˜¯ LangGraph ç›¸æ¯” LCEL `while` å¾ªç¯æœ€ä¼˜é›…çš„åœ°æ–¹ã€‚å†³ç­–é€»è¾‘ä¸æ‰§è¡Œé€»è¾‘è¢«å®Œå…¨åˆ†ç¦»ã€‚

```python
def should_continue(state: AgentState) -> Literal["improve_summary", "save_results", "end"]:
    """å†³ç­–å‡½æ•°ï¼šæ ¹æ®è¯„ä¼°ç»“æœå’Œè¿­ä»£æ¬¡æ•°å†³å®šä¸‹ä¸€æ­¥"""
    evaluation = state["evaluation"]  # è¯»å–ç›‘æ§ç»“æœ
    iterations = state["iterations"]
    max_iterations = state["max_iterations"]

    if evaluation.get("meets_goals", "").lower() == "æ˜¯":
        print("âœ… å†³ç­–: ç›®æ ‡å·²æ»¡è¶³ï¼Œå‡†å¤‡ä¿å­˜ç»“æœã€‚")
        return "save_results"
    elif iterations < max_iterations:
        print(f"ğŸ”„ å†³ç­–: ç›®æ ‡æœªæ»¡è¶³ï¼Œä½†æœªè¾¾æœ€å¤§è¿­ä»£æ¬¡æ•°({iterations}/{max_iterations})ï¼Œç»§ç»­æ”¹è¿›ã€‚")
        return "improve_summary"
    else:
        print(f"âš ï¸ å†³ç­–: å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°({max_iterations})ï¼Œç»“æŸæµç¨‹ã€‚")
        return "end"
```

*   **çº¯å‡½æ•°å†³ç­–**ï¼š`should_continue` æ˜¯ä¸€ä¸ªçº¯ç²¹çš„å†³ç­–å‡½æ•°ã€‚å®ƒåªè¯»å–çŠ¶æ€ï¼Œå¹¶æ ¹æ®é¢„è®¾çš„è§„åˆ™ï¼ˆç›®æ ‡æ˜¯å¦è¾¾æˆï¼Ÿè¿­ä»£æ¬¡æ•°æ˜¯å¦è¶…é™ï¼Ÿï¼‰è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²å°±æ˜¯ä¸‹ä¸€ä¸ªè¦å»çš„èŠ‚ç‚¹åç§°ã€‚
*   **å£°æ˜å¼æµç¨‹æ§åˆ¶**ï¼šåœ¨ `build_graph` ä¸­ï¼Œ`add_conditional_edges` å°†è¿™ä¸ªå†³ç­–å‡½æ•°ä¸å›¾çš„ç»“æ„ç»‘å®šåœ¨ä¸€èµ·ã€‚

```python
# æ·»åŠ æ¡ä»¶è¾¹ï¼šä»è¯„ä¼°èŠ‚ç‚¹åˆ°å†³ç­–
workflow.add_conditional_edges(
    "evaluate_summary",      # ä»å“ªä¸ªèŠ‚ç‚¹å¼€å§‹å†³ç­–
    should_continue,          # ä½¿ç”¨å“ªä¸ªå†³ç­–å‡½æ•°
    {                         # å†³ç­–ç»“æœä¸ç›®æ ‡èŠ‚ç‚¹çš„æ˜ å°„
        "improve_summary": "improve_summary",
        "save_results": "save_results",
        "end": END
    }
)

# æ·»åŠ å¾ªç¯è¾¹ï¼šä»æ”¹è¿›èŠ‚ç‚¹å›åˆ°è¯„ä¼°èŠ‚ç‚¹
workflow.add_edge("improve_summary", "evaluate_summary")
```

*   **æ™ºèƒ½é—­ç¯**ï¼šè¿™ä¸ªç»“æ„å½¢æˆäº†ä¸€ä¸ªå®Œç¾çš„**â€œè¡ŒåŠ¨-ç›‘æ§-å†³ç­–-å†è¡ŒåŠ¨â€**çš„æ™ºèƒ½é—­ç¯ã€‚
    1.  **è¡ŒåŠ¨**ï¼š`generate_summary_node` ç”Ÿæˆæ‘˜è¦ã€‚
    2.  **ç›‘æ§**ï¼š`evaluate_summary_node` è¯„ä¼°æ‘˜è¦ã€‚
    3.  **å†³ç­–**ï¼š`should_continue` å†³å®šæ˜¯ç»“æŸè¿˜æ˜¯ç»§ç»­ã€‚
    4.  **å†è¡ŒåŠ¨**ï¼šå¦‚æœç»§ç»­ï¼Œåˆ™æµå‘ `improve_summary_node`ã€‚
    5.  **å¾ªç¯**ï¼š`improve_summary_node` æ‰§è¡Œå®Œåï¼Œé€šè¿‡ `workflow.add_edge("improve_summary", "evaluate_summary")` è‡ªåŠ¨å›åˆ°ç¬¬2æ­¥ï¼ˆç›‘æ§ï¼‰ï¼Œå½¢æˆå¾ªç¯ã€‚

#### 5. æ”¹è¿›ï¼š`improve_summary_node` - åŸºäºåé¦ˆçš„è¡ŒåŠ¨

```python
def improve_summary_node(state: AgentState) -> AgentState:
    """èŠ‚ç‚¹5: æ”¹è¿›æ‘˜è¦"""
    summary = state["current_summary"]
    feedback = state["evaluation"].get("feedback", "éœ€è¦æ”¹è¿›") # <-- å…³é”®ï¼šä½¿ç”¨ç›‘æ§çš„åé¦ˆ
    goals = state["goals"]
    # ...
    # LLM æ ¹æ® feedback è¿›è¡Œæ”¹è¿›
    # ...
    return {"current_summary": improved_summary, "iterations": state["iterations"] + 1}
```

è¿™ä¸ªèŠ‚ç‚¹çš„æ™ºèƒ½ä¹‹å¤„åœ¨äºï¼Œå®ƒä¸æ˜¯ç›²ç›®åœ°é‡æ–°ç”Ÿæˆï¼Œè€Œæ˜¯**åˆ©ç”¨äº†ä¸Šä¸€æ­¥ç›‘æ§ç¯èŠ‚äº§ç”Ÿçš„ `feedback`**ã€‚è¿™ä½¿å¾—å®ƒçš„â€œæ”¹è¿›â€æ˜¯æœ‰çš„æ”¾çŸ¢çš„ï¼Œæ˜¯åŸºäºå¯¹â€œå·®è·â€çš„ç²¾ç¡®åˆ†æè€Œé‡‡å–çš„é’ˆå¯¹æ€§è¡ŒåŠ¨ã€‚

---

### æ€»ç»“ï¼šæ¨¡å¼ä¸ä»£ç çš„å®Œç¾æ˜ å°„

| â€œç›®æ ‡è®¾å®šä¸ç›‘æ§â€æ¨¡å¼æ¦‚å¿µ | å¯¹åº”çš„ä»£ç å®ç° | è§£é‡Š |
| :--- | :--- | :--- |
| **è®¾å®šç›®æ ‡** | `goals` åˆ—è¡¨ & `AgentState.goals` | å°†æ¸…æ™°ã€å¯è¡¡é‡çš„ç›®æ ‡æ³¨å…¥ Agent çš„çŠ¶æ€ä¸­ï¼Œä½œä¸ºå…¶è¡ŒåŠ¨çš„æœ€ç»ˆè¯„åˆ¤æ ‡å‡†ã€‚ |
| **è§„åˆ’ä¸æ‰§è¡Œ** | çº¿æ€§è¾¹ï¼ˆ`add_edge`ï¼‰ | `parse_pdf` -> `analyze_paper` -> `generate_summary` æ„æˆäº†åˆå§‹çš„ã€çº¿æ€§çš„æ‰§è¡Œè®¡åˆ’ã€‚ |
| **ç›‘æ§** | `evaluate_summary_node` | ä¸“é—¨çš„èŠ‚ç‚¹ï¼Œè´Ÿè´£å°†å½“å‰äº§å‡ºä¸ç›®æ ‡è¿›è¡Œå¯¹æ¯”ï¼Œç”Ÿæˆç»“æ„åŒ–çš„è¯„ä¼°æŠ¥å‘Šã€‚ |
| **åˆ¤æ–­æˆåŠŸ** | `evaluation['meets_goals']` | ç›‘æ§ç¯èŠ‚äº§ç”Ÿçš„æ˜ç¡®å¸ƒå°”å€¼ï¼Œæ˜¯ Agent åˆ¤æ–­è‡ªå·±æ˜¯å¦æˆåŠŸçš„æ ¸å¿ƒä¾æ®ã€‚ |
| **åé¦ˆ** | `evaluation['feedback']` | ç›‘æ§ç¯èŠ‚äº§ç”Ÿçš„å…·ä½“æ”¹è¿›å»ºè®®ï¼ŒæŒ‡å¯¼ä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ã€‚ |
| **å†³ç­–ä¸å¾ªç¯** | `should_continue` & `add_conditional_edges` | æ ¸å¿ƒæ§åˆ¶é€»è¾‘ï¼Œæ ¹æ®ç›‘æ§ç»“æœå†³å®šæ˜¯ç»“æŸæµç¨‹è¿˜æ˜¯è¿›å…¥æ”¹è¿›å¾ªç¯ã€‚ |
| **è¿­ä»£æ”¹è¿›** | `improve_summary_node` -> `evaluate_summary_node` çš„è¾¹ | åŸºäºåé¦ˆé‡‡å–è¡ŒåŠ¨ï¼Œå¹¶è‡ªåŠ¨è¿”å›ç›‘æ§ç¯èŠ‚ï¼Œå½¢æˆæ™ºèƒ½çš„é—­ç¯ã€‚ |

### ç»“è®º

é€šè¿‡ LangGraph çš„çŠ¶æ€å›¾æœºåˆ¶ï¼Œå°†â€œç›®æ ‡è®¾å®šä¸ç›‘æ§â€æ¨¡å¼ä»ä¸€ç§ç¼–ç¨‹æ€æƒ³ï¼Œ**ç‰©åŒ–ä¸ºä¸€ä¸ªå¯è¿è¡Œã€å¯è§‚æµ‹ã€å¯æ‰©å±•çš„æ™ºèƒ½å·¥ä½œæµ**ã€‚å®ƒæ¸…æ™°åœ°å±•ç¤ºäº†ï¼š

1.  **ç›®æ ‡é©±åŠ¨**ï¼šAgent çš„æ‰€æœ‰è¡Œä¸ºéƒ½å›´ç»•ç€è¾¾æˆé¢„è®¾çš„ç›®æ ‡ã€‚
2.  **è‡ªæˆ‘æ„ŸçŸ¥**ï¼šAgent èƒ½å¤Ÿè¯„ä¼°è‡ªå·±çš„äº§å‡ºä¸ç›®æ ‡ä¹‹é—´çš„å·®è·ã€‚
3.  **è‡ªä¸»å†³ç­–**ï¼šAgent èƒ½å¤Ÿæ ¹æ®è¯„ä¼°ç»“æœè‡ªä¸»å†³å®šä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ã€‚
4.  **æŒç»­æ”¹è¿›**ï¼šAgent èƒ½å¤Ÿåœ¨åé¦ˆå¾ªç¯ä¸­ä¸æ–­ä¼˜åŒ–ï¼Œç›´åˆ°è¾¾æˆç›®æ ‡ã€‚
